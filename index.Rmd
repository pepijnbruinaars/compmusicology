---
title: "Computational Musicology"
author: "Pepijn Bruinaars"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: yeti
---

```{r, setup}
library(tidyverse)
library(plotly)
library(spotifyr)
library(compmus)
library(gridExtra)

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

```{r, spotify_features}
corpus_features = readRDS(file = "data/corpus-features.RDS")
styled <- theme_bw() +
  theme(
    plot.title = element_text(face = "bold", size = 12),
    legend.background = element_rect(
      fill = "white",
      linewidth = 4,
      colour = "white"),
    axis.ticks = element_line(colour = "grey70", linewidth = 0.2),
    panel.grid.major = element_line(colour = "grey70", linewidth = 0.2),
    panel.grid.minor = element_blank()
  )
```

### Tempogram

```{r tempogram}
a_lydian <- readRDS(file = "data/a-lydian-data.RDS")

tempogram_1 <- readRDS(file = "data/tempogram-1.RDS")

dont_feel_anything <- readRDS(file = "data/dont-feel-anything-data.RDS")

tempogram_2 <- readRDS(file = "data/tempogram-2.RDS")

grid.arrange(tempogram_1, tempogram_2, nrow = 2)
```

***

[A Lydian](https://open.spotify.com/track/18U87POTjpJVmSUL8usDIO) is a beautiful piano piece by Analogue Dear, which also features some atmospheric pads. As you can see, the tempogram fails to find a consensus on the tempo, but it does seem to pick up smears of tempo around certain parts. This is due to the piece's only tempo-indicating feature being the piano, which is also played at various tempos.

Below, I have included a tempogram of San Holo's [i don't feel anything anymore](https://open.spotify.com/track/3P6VeiaresuGYqioZSpors), which starts of really soft, with some keys and pads being played. At around 50 seconds into the track, a heavy bass and some acoustic guitar is added which is being played at a constant tempo. Interestingly, the tempogram performs better in the first part, where there aren't many transient features yet. Up until 3 minutes into the song, it varies a bit between the calmer bits and heavier bass bits. After this mark, however, synths playing regularly timed arpeggios kick in, as well as a kick. After this, a drop happens and so the tempogram performs very well and you can see a clear line forming. After the drop, the pads come in again and the piece is ended in a very calm way.

I'm not sure how relevant the comparison is between these two tempograms, and if I should maybe just include one and leave the other, but I thought both were interesting, especially when following along while listening to the tracks.

### Introduction

This is my repository for the computational musicology course. During this course, I will be analyzing my personal [Spotify playlist](https://open.spotify.com/playlist/443PhwLJ63ci5JD8UpzNGf?si=373978fd923d44d5), and tracks which might be similar. It consists of 2466 (update at the end of course!!!) songs and an aggregated playtime of 143 hours and 18 minutes. This playlist started somewhere back in 2015 or 2016 and therefore tells you a lot about what I was going through in my life at specific times. One could say it functions as some sort of diary.

I will analyze the playlist on 3 or 6-month splits (yet to be determined!). This can be done by looking at the `date_added` variables which are returned when a GET request is done to the <https://api.spotify.com/v1/playlists/playlist_id> URL. I can also make a comparison between my so-called Top Items and recent tracks in my playlist.

The tracks in this corpus are very representative of each period since my music taste varies based on various factors which also contribute to particular feelings, e.g. seasons and an everchanging music taste.

### (A)typical tracks in the playlist

Most of the songs in the playlist will fall into the EDM/Pop genres, with Future Bass being a particularly frequent occurrence. Tracks that might be very typical for this playlist could include:

1.  [Light - San Holo](https://open.spotify.com/track/74Ru27B7Jx8mBt5MGvGLLv?si=930bed36366a4aab)

2.  [Shelter - Porter Robinson, Madeon](https://open.spotify.com/track/2CgOd0Lj5MuvOqzqdaAXtS?si=f4e921fc2da242e5)

3.  [I See You - Illenium, Said The Sky](https://open.spotify.com/track/5zRljvpgY1elGsc18Qp3tC?si=f1dcbe32b64a41c2)

These are tracks, the likes of which can be found through-out the entire playlist.

Meanwhile, standout tracks could be:

1.  [peace treaty - dobi, Oyeme](https://open.spotify.com/track/4MGgwugitqH7Zx8fBVrqip?si=49ae7ed8021943a6)

2.  [Happiness - JÃ³nsi, Alex Somers](https://open.spotify.com/track/56izuMFp1xj6IGXOh5efiY?si=342e0143e98f472f)

3.  [There Will Be Tears - Mr Hudson](https://open.spotify.com/track/1cSITnw1sufeq4hEFX1q2N?si=806763d6dfe644dd)

These tracks are all a bit sadder than the usual and mark periods such as COVID-lockdowns in the Netherlands. The genres as identified by everynoise.com, change from Future Bass to the likes of post-rock and other less energetic genres.

### Danceability and tempo

```{r, Danceability, echo=FALSE, message = FALSE, warning=FALSE, fig.width=10, fig.height=5}
plot1 <- corpus_features |> ggplot(
  aes(x = tempo,
      y = danceability,
      color = valence,
      )
    ) +
    geom_jitter(aes(alpha = 0.4,
                  text = paste("Track: ", paste(track.name,
                    map_chr(track.artists, ~ paste(.x$name, collapse = ", ")),
                    sep = " - "))))  +
  geom_smooth() +
  annotate("text", 200, 0.1, label = "Infinity") +
  scale_y_continuous(
    limits = c(0, 1)
  ) +
  styled +
  labs(
    x = "Tempo",
    y = "Danceability",
    colour = "Valence",
    title = "Danceability vs. Tempo and Valence",
  ) +
  guides(alpha = FALSE)

# Make the tooltip display only the tempo, danceability, track name and valence
ggplotly(plot1, tooltip = c("text", "x", "y", "color")) %>%
  layout(
    xaxis = list(title = "Tempo"),
    yaxis = list(title = "Danceability"),
    hovermode = "closest"
  )

```

***

I've included a plot with the *tempo*, *danceability* and *valence* of my corpus plotted against each other. I find this graph particularly interesting, since it shows a couple of defining characteristics from the corpus.

Most future bass and house music has a tempo range of 128-160 BPM. These ranges can be spotted easily in the graph, since there are distinct vertical lines which enclose the entirety of this range, with the vast majority of tracks having a tempo between 128 and 160 BPM.

However, the plotted trend line shows that as the tempo increases past the 128 BPM threshold, danceability (on average) seems to decrease, which is unexpected. I excted the danceability to increase as the tempo increases. This is because most high tempo (\>160 BPM) in this corpus are hard-dance tracks, which I've always considered danceable (albeit in a very different way than dancing to other genres). One such outlier is the track in the bottom-right corner: [Infinity](https://open.spotify.com/track/4l549wQMFj7HvlB7jzQnck?si=4202ba0f613f4ade) by Sefa and D-Block & S-te-Fan. This is a french-core track with intense kicks, which I would define as a highly danceable track.

### Chromagram of Infinity (Chebyshev)

```{r, chromagram}
infinity <- readRDS(file = "data/infinity-data.RDS") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

infinity |>
  mutate(pitches = map(pitches, compmus_normalise, "chebyshev")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

***

In this visualisation, I've chosen the outlier from my dataset I discussed previously, namely Infinity. Rendering the chromagram of this track somehow makes us able to see some structure in the track. The melodic intro and verses are easy to distinguish and all fit into a scale very well. However, the drops are also easy to discern, with the chroma features getting more spread out and centered around a few notes. This is especially notable during the second drop, where there are only three 'main' notes being played: C, C# and B. This distribution is mainly caused by the fact that this part consists mostly of kicks and heavy basslines, playing single notes. I'm interested in seeing what insights from next week will confirm the ones from this week.

### Analysis of gold away and gold away (heart version) by Former Hero

```{r formerhero}
original <-
  readRDS("data/gold-away-data.RDS") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )

heart <-
  readRDS("data/gold-away-heart-data.RDS")  |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )

original_plot <- bind_rows(
  original |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  original |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

heart_plot <- bind_rows(
  heart |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  heart |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

# Stack plots

grid.arrange(original_plot, heart_plot, nrow = 2)
```

***

Former Hero is a UK-based producer combining genres like post-rock and ambient with EDM from future bass to techno-like tracks. He released a lovely ambient piano piece called [Gold Away](https://open.spotify.com/track/0OtEOm1n6owWtb5h1Ncei4) in may 2021. In december 2022, he released an edit of the track called [gold away (Heart Version)](https://open.spotify.com/track/2NsOLbG8B9d2QuzKVJO5hZ). This is an edit of the original track, with a more upbeat tempo and overall higher danceability. It features floaty synths, but the main piano melody is still present throughout the entire track.

I've created 4 self similarity matrices for both tracks. The top two are created using chroma and timbre features of the original track, while the bottom 2 are created using the edited version.

### Cepstogram

```{r, cepstogram}
bzt <-
  get_tidy_audio_analysis("4pWXN0gyIOqxODSGGgAMr4") |> # Change URI.
  # get_tidy_audio_analysis("5uL2NjzkGMbDcaKKrCdFzG") |>
  compmus_align(beats, segments) |>                     # Change `bars`
  select(beats) |>                                      #   in all three
  unnest(beats) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bzt |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +
  theme_classic()
```

***

Text

### Self-similarity matrix

```{r, ssm}
bzt |>
  compmus_self_similarity(pitches, "aitchison") |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

***

This is a self-similarity matrix of the song Still Together, which is (coincidentally) made by me and a friend. In the track, we used the same chord progression throughout, and only changed this in the outro, which can be clearly seen by the black box on the end of the main diagonal. The two drops can also be determined by the two darker section in the middle. This is mostly due to new melodic elements being introduced.

### How different are Gold Away and its edit?

```{r, gold_away_vs_gold_away_edit}
gold_away <-
  readRDS("data/gold-away-data.RDS") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"
      )
  )

gold_heart <-
  readRDS("data/gold-away-heart-data.RDS") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"
      )
  )

original_chord <- gold_away |>
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "euclidean"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")

heart_chord <- gold_heart |>
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "aitchison",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")

grid.arrange(original_chord, heart_chord, nrow = 2)
```

***

I've included 2 chordograms of 2 different tracks. They're made by Former Hero, who is a producer of future bass and vapor twitch according to everynoise.com. The first track is a beautiful piece called [Gold Away](https://open.spotify.com/track/0OtEOm1n6owWtb5h1Ncei4) (definitely check it out if you get the chance), and its chordogram is on top. It is a very atmospheric piano track, which starts with some grainy piano sounds. This is visible in the chordogram, as the first chord is D major. Because of the slow nature of the track, we can easily discern the rest of the chords.

The second track is an edit of this track, called [gold away - heart version](https://open.spotify.com/track/2NsOLbG8B9d2QuzKVJO5hZ). This track is a more "housey" version which samples the original. Its chordogram is a bit difficult to read, but it is clear that in the edit, the piece is pitched up with 2 semitones. Since the track is also faster paced, and is longer than the original, it is harder to discern the chords that are being played. However, the same pattern is still visible, it's just in a higher place compared to the first chordogram.

Chordograms are a good way to compare these two tracks, as they are both by the same artist and are very similar in nature.

### Does the Bitbird sound change over the years? (Track level summaries) {data-commentary-width="400"}

```{r, bitbird}
gf1 <- readRDS(file = "data/gf1-data.RDS")
gf2 <- readRDS(file = "data/gf2-data.RDS")
gf3 <- readRDS(file = "data/gf3-data.RDS")
gf4 <- readRDS(file = "data/gf4-data.RDS")
bitbird <-
  gf1 |>
  mutate(album = "Gouldian Finch") |>
  bind_rows(gf2 |> mutate(album = "Gouldian Finch 2")) |>
  bind_rows(gf3 |> mutate(album = "Gouldian Finch 3")) |>
  bind_rows(gf4 |> mutate(album = "Gouldian Finch 4"))

# I want to add a trendline for each timbre category
bitbird_plot <- bitbird |>
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) |>
  select(album, timbre) |>
  compmus_gather_timbre() |>
  ggplot(aes(x = basis, y = value, fill = album)) +
  geom_violin() +
  geom_smooth(method = "lm", se = FALSE) +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Album")

ggplotly(bitbird_plot)
```

***

These are the results of the analysis of the tracks of 4 albums. These albums are compilations of tracks by many different artists, and is compiled by the label Bitbird, which is a label that I have been following for a while and it has a massive footprint on my playlist. Because of this, they are very representative of my playlist. Almost all tracks in these compilations can be found in my playlist. The compilations are called '[Gouldian Finch](https://open.spotify.com/album/2zxH8phePC3VEFDPJV4kFq)', '[Gouldian Finch 2](https://open.spotify.com/album/4jCNXDzme5yj9WhGTh76O8)', '[Gouldian Finch 3](https://open.spotify.com/album/3GDnGYJDgsWLUuxypxmNEI)' and '[Gouldian Finch 4](https://open.spotify.com/album/4GX6Laa0cgCbiKjJKg7DfH)'. The albums were released in 2016, 2017, 2019, and 2021 respectively.

I have plotted the distribution of the Spotify Timbre Coefficients for each album. These coefficients are hard to interpret, but they are a good way to compare the timbre of the tracks in the albums. As you can see, the distributions for the most part are very similar, but there are also a few trends that can be seen. For example, we can see that the distribution of coefficient 2 is clearly going down. Over the years, although the distribution of it in the first compilation is very widespread. The second coefficent is associated with the brightness of the track, so according to this analysis, one could say that the overall brightness coefficent of the tracks is steadily decreasing. This is also a trend that can be heard, when listening to the compilations.

This same downward trend can be seen in the distributions of the 3rd coefficient. This coefficient is associated with the flatness of the sounds, which is a way to quantify how much a sound resembles a pure tone, as opposed to being noise-like. This is a very interesting trend, because the music in the compilations is indeed becoming more and more organic and "lo-fi noisy" over the years.
