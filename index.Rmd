---
title: "Computational Musicology"
author: "Pepijn Bruinaars"
date: "2023-02-13"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: yeti
---
```{r, setup}
library(tidyverse)
library(plotly)
library(spotifyr)
library(compmus)
library(gridExtra)

corpus_features <- get_playlist_audio_features("", "443PhwLJ63ci5JD8UpzNGf")
styled <- theme_bw() +
  theme(
    plot.title = element_text(face = "bold", size = 12),
    legend.background = element_rect(
      fill = "white",
      linewidth = 4,
      colour = "white"),
    axis.ticks = element_line(colour = "grey70", linewidth = 0.2),
    panel.grid.major = element_line(colour = "grey70", linewidth = 0.2),
    panel.grid.minor = element_blank()
  )

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

### Introduction

This is my repository for the computational musicology course. During this course, I will be analyzing my personal [Spotify playlist](https://open.spotify.com/playlist/443PhwLJ63ci5JD8UpzNGf?si=373978fd923d44d5). It consists of 2466 songs and an aggregated playtime of 143 hours and 18 minutes. This playlist started somewhere back in 2015 or 2016 and therefore tells you a lot about what I was going through in my life at specific times. One could say it functions as some sort of diary.

I will analyze the playlist on 3 or 6-month splits (yet to be determined!). This can be done by looking at the `date_added` variables which are returned when a GET request is done to the <https://api.spotify.com/v1/playlists/playlist_id> URL. I can also make a comparison between my so-called Top Items and recent tracks in my playlist.

The tracks in this corpus are very representative of each period since my music taste varies based on various factors which also contribute to particular feelings, e.g. seasons and an everchanging music taste.

### (A)typical tracks in the playlist

Most of the songs in the playlist will fall into the EDM/Pop genres, with Future Bass being a particularly frequent occurrence. Tracks that might be very typical for this playlist could include:

1.  [Light - San Holo](https://open.spotify.com/track/74Ru27B7Jx8mBt5MGvGLLv?si=930bed36366a4aab)

2.  [Shelter - Porter Robinson, Madeon](https://open.spotify.com/track/2CgOd0Lj5MuvOqzqdaAXtS?si=f4e921fc2da242e5)

3.  [I See You - Illenium, Said The Sky](https://open.spotify.com/track/5zRljvpgY1elGsc18Qp3tC?si=f1dcbe32b64a41c2)

These are tracks, the likes of which can be found through-out the entire playlist.

Meanwhile, standout tracks could be:

1.  [peace treaty - dobi, Oyeme](https://open.spotify.com/track/4MGgwugitqH7Zx8fBVrqip?si=49ae7ed8021943a6)

2.  [Happiness - JÃ³nsi, Alex Somers](https://open.spotify.com/track/56izuMFp1xj6IGXOh5efiY?si=342e0143e98f472f)

3.  [There Will Be Tears - Mr Hudson](https://open.spotify.com/track/1cSITnw1sufeq4hEFX1q2N?si=806763d6dfe644dd)

These tracks are all a bit sadder than the usual and mark periods such as COVID-lockdowns in the Netherlands. The genres as identified by everynoise.com, change from Future Bass to the likes of post-rock and other less energetic genres.

### Danceability and tempo

```{r, Danceability, echo=FALSE, message = FALSE, warning=FALSE, fig.width=10, fig.height=5}
plot1 <- corpus_features |> ggplot(
  aes(x = tempo,
      y = danceability,
      color = valence,
      )
    ) +
    geom_jitter(aes(alpha = 0.4,
                  text = paste("Track: ", paste(track.name,
                    map_chr(track.artists, ~ paste(.x$name, collapse = ", ")),
                    sep = " - "))))  +
  geom_smooth() +
  annotate("text", 200, 0.1, label = "Infinity") +
  scale_y_continuous(
    limits = c(0, 1)
  ) +
  styled +
  labs(
    x = "Tempo",
    y = "Danceability",
    colour = "Valence",
    title = "Danceability vs. Tempo and Valence",
  ) +
  guides(alpha = FALSE)

# Make the tooltip display only the tempo, danceability, track name and valence
ggplotly(plot1, tooltip = c("text", "x", "y", "color")) %>%
  layout(
    xaxis = list(title = "Tempo"),
    yaxis = list(title = "Danceability"),
    hovermode = "closest"
  )

```

***

I've included a plot with the *tempo*, *danceability* and *valence* of my corpus plotted against each other. I find this graph particularly interesting, since it shows a couple of defining characteristics from the corpus.

Most future bass and house music has a tempo range of 128-160 BPM. These ranges can be spotted easily in the graph, since there are distinct vertical lines which enclose the entirety of this range, with the vast majority of tracks having a tempo between 128 and 160 BPM.

However, the plotted trend line shows that as the tempo increases past the 128 BPM threshold, danceability (on average) seems to decrease, which is unexpected. I excted the danceability to increase as the tempo increases. This is because most high tempo (\>160 BPM) in this corpus are hard-dance tracks, which I've always considered danceable (albeit in a very different way than dancing to other genres). One such outlier is the track in the bottom-right corner: [Infinity](https://open.spotify.com/track/4l549wQMFj7HvlB7jzQnck?si=4202ba0f613f4ade) by Sefa and D-Block & S-te-Fan. This is a french-core track with intense kicks, which I would define as a highly danceable track. I will look to find out what defines a danceable track to Spotify.

### Chromagram of Infinity (Chebyshev)

```{r, chromagram}
chroma <- get_tidy_audio_analysis("4l549wQMFj7HvlB7jzQnck") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

chroma |>
  mutate(pitches = map(pitches, compmus_normalise, "chebyshev")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

***

In this visualisation, I've chosen the outlier from my dataset I discussed previously, namely Infinity. Rendering the chromagram of this track somehow makes us able to see some structure in the track. The melodic intro and verses are easy to distinguish and all fit into a scale very well. However, the drops are also easy to discern, with the chroma features getting more spread out and centered around a few notes. This is especially notable during the second drop, where there are only three 'main' notes being played: C, C# and B. This distribution is mainly caused by the fact that this part consists mostly of kicks and heavy basslines, playing single notes. I'm interested in seeing what insights from next week will confirm the ones from this week.

### Analysis of gold away and gold away (heart version) by Former Hero

```{r formerhero}
original <-
  get_tidy_audio_analysis("0OtEOm1n6owWtb5h1Ncei4") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )

heart <-
get_tidy_audio_analysis("2NsOLbG8B9d2QuzKVJO5hZ") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )

original_plot <- bind_rows(
  original |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  original |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

heart_plot <- bind_rows(
  heart |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  heart |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

# Stack plots

grid.arrange(original_plot, heart_plot, nrow = 2)
```

***

Former Hero is a UK-based producer combining genres like post-rock and 
ambient with EDM from future bass to techno-like tracks. He released a lovely ambient piano piece called 
[Gold Away](https://open.spotify.com/track/0OtEOm1n6owWtb5h1Ncei4) in may 2021.
In december 2022, he released an edit of the track called 
[gold away (Heart Version)](https://open.spotify.com/track/2NsOLbG8B9d2QuzKVJO5hZ). This is an edit of the original track,
with a more upbeat tempo and overall higher danceability. It features floaty synths, but the main
piano melody is still present throughout the entire track.

I've created 4 self similarity matrices for both tracks. The top two are created using chroma and timbre features of the original track, while the 
bottom 2 are created using the edited version.

### Cepstogram

```{r, cepstogram}
bzt <-
  get_tidy_audio_analysis("4pWXN0gyIOqxODSGGgAMr4") |> # Change URI.
  # get_tidy_audio_analysis("5uL2NjzkGMbDcaKKrCdFzG") |>
  compmus_align(beats, segments) |>                     # Change `bars`
  select(beats) |>                                      #   in all three
  unnest(beats) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bzt |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +
  theme_classic()
```

***

Text

### Self-similarity matrix

```{r, ssm}
bzt |>
  compmus_self_similarity(pitches, "aitchison") |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

***

This is a self-similarity matrix of the song Still Together, which is (coincidentally) made by me and a friend. In the track, we used the same chord progression throughout, and only changed this in the outro, which can be clearly seen by the black box on the end of the main diagonal. The two drops can also be determined by the two darker section in the middle. This is mostly due to new melodic elements being introduced.